{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Testing the SIGA Model Without Fine-tuning**\n",
    "## In this notebook, we will evaluate the performance of the pre-trained SIGA model (Microsoft DeBERTa) on our dataset.\n",
    "## We will compare its performance with a fine-tuned version to assess the impact of fine-tuning on classification accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1. Install Required Libraries**\n",
    "### Ensure that scikit-learn is installed before proceeding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /home/wtto/Documents/HHU/Third_Semester/NLI_AP/NLIvenv/lib/python3.12/site-packages (1.6.1)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /home/wtto/Documents/HHU/Third_Semester/NLI_AP/NLIvenv/lib/python3.12/site-packages (from scikit-learn) (2.1.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /home/wtto/Documents/HHU/Third_Semester/NLI_AP/NLIvenv/lib/python3.12/site-packages (from scikit-learn) (1.15.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/wtto/Documents/HHU/Third_Semester/NLI_AP/NLIvenv/lib/python3.12/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/wtto/Documents/HHU/Third_Semester/NLI_AP/NLIvenv/lib/python3.12/site-packages (from scikit-learn) (3.5.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2. Load the Dataset**\n",
    "### Read the dataset containing premises, statements, and labels for Natural Language Inference (NLI).\n",
    "### (remember to replace the path to your data file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Scale</th>\n",
       "      <th>premise</th>\n",
       "      <th>alternative</th>\n",
       "      <th>statement</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1889</th>\n",
       "      <td>special</td>\n",
       "      <td>if you think you have given your best effort.....</td>\n",
       "      <td>tired</td>\n",
       "      <td>i'm still tired but i can't fall back asleep</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1890</th>\n",
       "      <td>adequate</td>\n",
       "      <td>i'm using the next one up i think ? it's prett...</td>\n",
       "      <td>wary</td>\n",
       "      <td>warne wary of risking longevity at millers by ...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1891</th>\n",
       "      <td>intelligent</td>\n",
       "      <td>a woman that's intelligent is pretty damn attr...</td>\n",
       "      <td>special</td>\n",
       "      <td>the worst feeling is when someone makes you fe...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1892</th>\n",
       "      <td>allowed</td>\n",
       "      <td>senior portaits are tomorrow by last name. guy...</td>\n",
       "      <td>few</td>\n",
       "      <td>and the fact people are able to say \"no.\" is b...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1893</th>\n",
       "      <td>small</td>\n",
       "      <td>a very small sample of today's work out lol .....</td>\n",
       "      <td>some</td>\n",
       "      <td>some people make the mistake of thinking that ...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Scale                                            premise  \\\n",
       "1889      special  if you think you have given your best effort.....   \n",
       "1890     adequate  i'm using the next one up i think ? it's prett...   \n",
       "1891  intelligent  a woman that's intelligent is pretty damn attr...   \n",
       "1892      allowed  senior portaits are tomorrow by last name. guy...   \n",
       "1893        small  a very small sample of today's work out lol .....   \n",
       "\n",
       "     alternative                                          statement    label  \n",
       "1889       tired       i'm still tired but i can't fall back asleep  neutral  \n",
       "1890        wary  warne wary of risking longevity at millers by ...  neutral  \n",
       "1891     special  the worst feeling is when someone makes you fe...  neutral  \n",
       "1892         few  and the fact people are able to say \"no.\" is b...  neutral  \n",
       "1893        some  some people make the mistake of thinking that ...  neutral  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv('/home/wtto/Downloads/evaluation_dataset.csv')\n",
    "display(df.tail())  # Display first few rows of the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3. Load Pre-trained DeBERTa Model and Tokenizer**\n",
    "### We use the `\"microsoft/deberta-base-mnli\"` model for sequence classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wtto/Documents/HHU/Third_Semester/NLI_AP/NLIvenv/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at microsoft/deberta-base-mnli were not used when initializing DebertaForSequenceClassification: ['config']\n",
      "- This IS expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DebertaForSequenceClassification(\n",
       "  (deberta): DebertaModel(\n",
       "    (embeddings): DebertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=0)\n",
       "      (LayerNorm): DebertaLayerNorm()\n",
       "      (dropout): StableDropout()\n",
       "    )\n",
       "    (encoder): DebertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x DebertaLayer(\n",
       "          (attention): DebertaAttention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): DebertaLayerNorm()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): DebertaLayerNorm()\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (rel_embeddings): Embedding(1024, 768)\n",
       "    )\n",
       "  )\n",
       "  (pooler): ContextPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): StableDropout()\n",
       "  )\n",
       "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
       "  (dropout): StableDropout()\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"microsoft/deberta-base-mnli\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "model.eval()  # Set model to evaluation mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4. Move Model to GPU if Available**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DebertaForSequenceClassification(\n",
       "  (deberta): DebertaModel(\n",
       "    (embeddings): DebertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=0)\n",
       "      (LayerNorm): DebertaLayerNorm()\n",
       "      (dropout): StableDropout()\n",
       "    )\n",
       "    (encoder): DebertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x DebertaLayer(\n",
       "          (attention): DebertaAttention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): DebertaLayerNorm()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): DebertaLayerNorm()\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (rel_embeddings): Embedding(1024, 768)\n",
       "    )\n",
       "  )\n",
       "  (pooler): ContextPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): StableDropout()\n",
       "  )\n",
       "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
       "  (dropout): StableDropout()\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **5. Define Batch Processing Parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8  # Adjust based on available GPU memory\n",
    "predicted_labels = []  # Store model predictions\n",
    "true_labels = []  # Store ground truth labels\n",
    "\n",
    "label_map = {\n",
    "    \"contradiction\": 0,\n",
    "    \"neutral\": 1,\n",
    "    \"entailment\": 2\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **6. Process the Dataset in Batches**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    }
   ],
   "source": [
    "# Process the dataset in batches\n",
    "for i in range(0, len(df), batch_size):\n",
    "    batch_texts = df[\"premise\"].iloc[i:i+batch_size].tolist()\n",
    "    batch_statements = df[\"statement\"].iloc[i:i+batch_size].tolist()\n",
    "    batch_true_labels = df[\"label\"].iloc[i:i+batch_size].tolist()\n",
    "\n",
    "    # Tokenize in smaller batches\n",
    "    inputs = tokenizer(batch_texts, batch_statements, truncation=True, padding=True, return_tensors=\"pt\")\n",
    "    inputs = {key: val.to(device) for key, val in inputs.items()}\n",
    "\n",
    "    # Get predictions\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "    logits = outputs.logits\n",
    "    predicted_classes = torch.argmax(logits, dim=-1).tolist()\n",
    "\n",
    "    # Map model predictions to labels\n",
    "    batch_predicted_labels = predicted_classes  # Keep them as integers\n",
    "\n",
    "\n",
    "    # Append the batch predictions and true labels to the overall list\n",
    "    predicted_labels.extend(batch_predicted_labels)\n",
    "    true_labels.extend([label_map[lbl] for lbl in batch_true_labels])  # Ensure integer labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **7. Evaluate Model Performance**\n",
    "### Add predictions to the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "contradiction       0.01      0.00      0.00       441\n",
      "      neutral       0.20      0.68      0.30       500\n",
      "   entailment       0.00      0.00      0.00       953\n",
      "\n",
      "     accuracy                           0.18      1894\n",
      "    macro avg       0.07      0.23      0.10      1894\n",
      " weighted avg       0.05      0.18      0.08      1894\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df[\"predicted_label\"] = predicted_labels\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(true_labels, predicted_labels, labels=[0,1,2], target_names=[\"contradiction\", \"neutral\", \"entailment\"]))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLIvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
